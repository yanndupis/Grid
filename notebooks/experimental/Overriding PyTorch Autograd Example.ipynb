{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable, Function\n",
    "import inspect\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# import functools\n",
    "# TODO: Use functools.wrap to get original function/method dir attributes\n",
    "\n",
    "class EncryptedAdd(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        return a+b\n",
    "        # compute a + b on encrypted data - they are regular PyTorch tensors\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        grad_out = VariableProxy(grad_out.data)\n",
    "        return grad_out.var,grad_out.var\n",
    "        # not grad_out operators are overloaded\n",
    "        \n",
    "class EncryptedMult(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        ctx.save_for_backward(a,b)       \n",
    "        return a*b\n",
    "        # compute a * b on encrypted data - they are regular PyTorch tensors\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        a,b = ctx.saved_tensors\n",
    "        grad_out = grad_out\n",
    "        return Variable(grad_out.data*b),Variable(grad_out.data*a)\n",
    "        # not grad_out operators are overloaded\n",
    "\n",
    "class VariableProxy(object):\n",
    "    \n",
    "    def __init__(self, var, requires_grad=True):\n",
    "        self.var = Variable(var,requires_grad=requires_grad)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return (EncryptedAdd.apply(self.var, other.var))\n",
    "    \n",
    "    def __mul__(self,other):\n",
    "        return (EncryptedMult.apply(self.var, other.var))\n",
    "    \n",
    "    def grad(self):\n",
    "        return self.var.grad\n",
    "    \n",
    "x = VariableProxy(torch.FloatTensor([1,1,1]),requires_grad=True)\n",
    "y = VariableProxy(torch.FloatTensor([2,3,4]),requires_grad=True)\n",
    "\n",
    "z = x * y\n",
    "\n",
    "z.backward(torch.FloatTensor([1]))\n",
    "\n",
    "x.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
