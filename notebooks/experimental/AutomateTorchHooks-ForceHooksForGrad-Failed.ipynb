{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAILED EXPERIMENT -- forcing `Variable.register_hook` during `__init__` and `__new__` to try to register grad Variables with the worker when they're created during calls to `backward` downstream.\n",
    "\n",
    "Could be possible to fix, and would result in cleaner code if we can, but not otherwise necessary at the prototyping stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires using PyTorch v0.3.1.  Somewhere between 0.3.1 and 0.4.0 parts of the backend were significantly rewritten, preventing us from performing the following hacks. (Likely has to do with them fusing Variable and Tensor).  That may change once their new API stabilizes.\n",
    "\n",
    "This work has led me to believe that we'll eventually just have one mode that will do everything we need (including keeping track of the model's version control tree for tracking contribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Main event](#start)\n",
    "[Wrappers](#wrap)<br>\n",
    "[init and repr](#initrepr)<br>\n",
    "[Helpers](#helps)<br>\n",
    "[Hooking](#hook)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Minimal tests for each Torch object](#tests)\n",
    "[FloatTensor](#float_test)<br>\n",
    "[DoubleTensor](#double_test)<br>\n",
    "[HalfTensor](#half_test)<br>\n",
    "[ByteTensor](#byte_test)<br>\n",
    "[CharTensor](#char_test)<br>\n",
    "[ShortTensor](#short_test)<br>\n",
    "[IntTensor](#int_test)<br>\n",
    "[LongTensor](#long_test)<br>\n",
    "[Variable](#var_test) (TODO) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from grid.clients.torch import TorchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mUPDATE: \u001b[0mConnecting to IPFS... this can take a few seconds...\n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mConnected!!! - My ID: QmXJMbiCqQdFCUjwy63GMUDDKCfEabJRYo2RHPjheCW8mc\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mQuerying known workers...\n",
      "\tWORKER: /p2p-circuit/ipfs/QmQabt3SWuDvjse9z7GAcH2BGQv4wH8bumkd4x5oXN2obX...\u001b[32mSUCCESS!!!\u001b[0m\n",
      "\tWORKER: /p2p-circuit/ipfs/QmXkWUybbTnfvFH8SUcrug6RGTLYTB23gSockKLxueR1vQ...\u001b[32mSUCCESS!!!\u001b[0m\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mSearching for IPFS nodes - 27 found overall - 1 are OpenMined workers          \n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mFound 1 OpenMined nodes!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "known_workers=['/p2p-circuit/ipfs/QmQabt3SWuDvjse9z7GAcH2BGQv4wH8bumkd4x5oXN2obX','/p2p-circuit/ipfs/QmXkWUybbTnfvFH8SUcrug6RGTLYTB23gSockKLxueR1vQ']\n",
    "client = TorchClient(verbose = False, include_github_known_workers=False, known_workers = known_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_self = client.services['torch_service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import inspect\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import re\n",
    "from functools import wraps, partial, partialmethod\n",
    "from types import *\n",
    "from collections import OrderedDict\n",
    "import imp\n",
    "# from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorvar_types = [torch.FloatTensor,\n",
    "                torch.DoubleTensor,\n",
    "                torch.HalfTensor,\n",
    "                torch.ByteTensor,\n",
    "                torch.CharTensor,\n",
    "                torch.ShortTensor,\n",
    "                torch.IntTensor,\n",
    "                torch.LongTensor,\n",
    "                torch.autograd.variable.Variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='start'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Event [(top)](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrap'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers.\n",
    "`assign_workers_function` is for functions (e.g. `torch.add(x ,y)`)<br>`assign_workers_method` is for methods (e.g. `x.add(y)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_workers_function(worker_ids):\n",
    "    def decorate(func):\n",
    "        @wraps(func)\n",
    "        def send_to_workers(*args, **kwargs):\n",
    "            part = func(*args, **kwargs)\n",
    "            command = compile_command(part)\n",
    "            tensorvars = get_tensorvars(command)\n",
    "            has_remote, multiple_owners = check_tensorvars(tensorvars)\n",
    "            if not has_remote:\n",
    "                result = part.func(*args, **kwargs)\n",
    "                if type(result) in tensorvar_types:\n",
    "                    result = service_self.register_object(result, False)\n",
    "                return result\n",
    "            elif multiple_owners:\n",
    "                raise NotImplementedError('MPC not yet implemented: Torch objects need to be on the same machine in order to compute with them.')\n",
    "            else:\n",
    "                for worker in worker_ids:\n",
    "                    print(\"Placeholder print for sending command to worker {}\".format(worker))\n",
    "                    args, kwargs = send_command(command)\n",
    "                receive_commands(worker_ids)  ## Probably needs to happen async\n",
    "                return args, kwargs\n",
    "        return send_to_workers\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_workers_method(worker_ids):\n",
    "    def decorate(method):\n",
    "        @wraps(method)\n",
    "        def send_to_workers(self, *args, **kwargs):\n",
    "            part = method(self, *args, **kwargs)\n",
    "            if self.is_pointer_to_remote:\n",
    "                command = compile_command(part)\n",
    "                for worker in worker_ids:\n",
    "                    print(\"Placeholder print for sending command to worker {}\".format(worker))\n",
    "                    args, kwargs = send_command(command)\n",
    "                receive_commands(worker_ids)  ## Probably needs to happen async\n",
    "                return args, kwargs\n",
    "            else:\n",
    "                #import ipdb; ipdb.set_trace()\n",
    "                result = part.func(self, *args, **kwargs)\n",
    "                if type(result) == torch.autograd.variable.Variable:\n",
    "                    result.data_registered = False\n",
    "                    result.grad_registered = False\n",
    "                if type(result) in tensorvar_types and not hasattr(result, 'owner'):\n",
    "                    my_service = self.worker.services['torch_service']\n",
    "                    result = my_service.register_object(result, False)\n",
    "                return result\n",
    "        return send_to_workers\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrappers that do nothing except pass a copy of the underlying torch function/method, as well as any args/kwargs supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_func_args(func):\n",
    "    @wraps(func)\n",
    "    def pass_args(*args, **kwargs):\n",
    "        return partial(func, *args, **kwargs)\n",
    "    return pass_args\n",
    "\n",
    "def pass_method_args(method):\n",
    "    @wraps(method)\n",
    "    def pass_args(*args, **kwargs):\n",
    "        return partialmethod(method, *args, **kwargs)\n",
    "    return pass_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='initrepr'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init, repr, new\n",
    "Treat `__init__`, `__repr__`, and `__new__` specially in certain cases.  The `__init__` registers the object with the worker, the `__repr__` replaces torch's default pretty printing with a (less) pretty printing of our own, and `__new__` makes sure that new objects created in C as a result of computations are registered as well, even though their `__init__` is never called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_tensor___init__(service_self, tensor_type):\n",
    "    def new___init__(self, *args):\n",
    "        super(tensor_type, self).__init__()\n",
    "        self = service_self.register_object(self,False)\n",
    "\n",
    "    tensor_type.__init__ = new___init__\n",
    "    \n",
    "def hook_tensor___new__(service_self, tensor_type):\n",
    "    tensor_type.old___new__ = tensor_type.__new__\n",
    "    def new___new__(cls, *args, **kwargs):\n",
    "        result = tensor_type.old___new__(cls, *args,  **kwargs)\n",
    "        result = service_self.register_object(result, False)\n",
    "        return result\n",
    "    \n",
    "    tensor_type.__new__ = new___new__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_var_force_hook():\n",
    "    def force_hook(self, hook):\n",
    "        if self._backward_hooks is None:\n",
    "            self._backward_hooks = OrderedDict()\n",
    "            if self.grad_fn is not None:\n",
    "                self.grad_fn._register_hook_dict(self)\n",
    "        handle = torch.utils.hooks.RemovableHandle(self._backward_hooks)\n",
    "        self._backward_hooks[handle.id] = hook\n",
    "        return handle\n",
    "    torch.autograd.variable.Variable.force_hook = force_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_grad_attr(grad, attr:str):\n",
    "    new_grad = grad\n",
    "    setattr(new_grad, attr, False)\n",
    "    return new_grad\n",
    "\n",
    "def hook_var___init__(service_self):\n",
    "    def new___init__(self, *args, **kwargs):\n",
    "        super(torch.autograd.variable.Variable, self).__init__(*args, **kwargs)\n",
    "        self.data_registered =  False\n",
    "        self.grad_registered =  False\n",
    "        \n",
    "        self.force_hook(lambda grad: set_grad_attr(grad, 'data_registered'))\n",
    "        self.force_hook(lambda grad: set_grad_attr(grad, 'grad_registered'))\n",
    "#         if not hasattr(self.data, 'owner'):\n",
    "#             self.data = service_self.register_object(self.data,False)\n",
    "#             self.data_registered = True\n",
    "#         if self.grad is not None and not hasattr(self.grad, 'owner'):\n",
    "#             self.grad = service_self.register_object(self.grad,False)\n",
    "#             self.grad_registered = True\n",
    "\n",
    "    torch.autograd.variable.Variable.__init__ = new___init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Make sure that we're registering as little as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_var___new__(service_self):\n",
    "    old_var___new__ = torch.autograd.variable.Variable.__new__\n",
    "    def new___new__(cls, *args, **kwargs):\n",
    "        result = old_var___new__(cls, *args,  **kwargs)\n",
    "        result = service_self.register_object(result, False)\n",
    "        result.data_registered = False\n",
    "        result.grad_registered = False\n",
    "        result.force_hook(lambda grad: set_grad_attr(grad, 'data_registered'))\n",
    "        result.force_hook(lambda grad: set_grad_attr(grad, 'grad_registered'))\n",
    "        return result\n",
    "    \n",
    "    torch.autograd.variable.Variable.__new__ = new___new__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_var_contents(service_self):\n",
    "    torch.autograd.variable.Variable.old_data = torch.autograd.variable.Variable.data\n",
    "    torch.autograd.variable.Variable.old_grad = torch.autograd.variable.Variable.grad\n",
    "    @property\n",
    "    def new_data(self):\n",
    "        if not self.data_registered:\n",
    "            self.old_data = service_self.register_object(self.old_data, False)\n",
    "            self.data_registered = True\n",
    "        return self.old_data\n",
    "    \n",
    "    @property\n",
    "    def new_grad(self):\n",
    "        if not self.grad_registered:\n",
    "            if self.old_grad is not None:\n",
    "                self.old_grad = service_self.register_object(self.old_grad, False)\n",
    "                self.grad_registered = True\n",
    "        return self.old_grad\n",
    "    \n",
    "    torch.autograd.variable.Variable.data = new_data\n",
    "    torch.autograd.variable.Variable.grad = new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_tensor___repr__(service_self, tensor_type):\n",
    "        def __repr__(self):\n",
    "            if(service_self.worker.id == self.owner):\n",
    "                return self.old__repr__()\n",
    "            else:\n",
    "                return \"[ {} - Location:{} ]\".format(tensor_type, self.owner)\n",
    "\n",
    "        # if haven't reserved the actual __repr__ function - reserve it now\n",
    "        try:\n",
    "            tensor_type.old__repr__\n",
    "        except:\n",
    "            tensor_type.old__repr__ = tensor_type.__repr__\n",
    "            \n",
    "\n",
    "        tensor_type.__repr__ = __repr__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='helps'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorvars(command):\n",
    "    args = command['args']\n",
    "    kwargs = command['kwargs']\n",
    "    arg_types = command['arg_types']\n",
    "    kwarg_types = command['kwarg_types']\n",
    "    tensorvar_args = [args[i] for i in range(len(args)) if arg_types[i] in tensorvar_types]\n",
    "    tensorvar_kwargs = [kwargs[i][1] for i in range(len(kwargs)) if kwarg_types[i] in tensorvar_types]\n",
    "    return tensorvar_args + tensorvar_kwargs\n",
    "    \n",
    "def check_tensorvars(tensorvars):\n",
    "    has_remote = any([tensorvar.is_pointer_to_remote for tensorvar in tensorvars])\n",
    "    multiple_owners = len(set([tensorvar.owner for tensorvar in tensorvars])) != 1\n",
    "    return has_remote, multiple_owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are unfinished.  They'll need to be integrated into the rest of Grid after this prototype is ready for merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_command(command):\n",
    "    print(command['command'])\n",
    "    print([type(arg) for arg in command['args']])\n",
    "    print([type(pair) for pair in command['kwargs']])\n",
    "    print('===========')\n",
    "    print()\n",
    "    return command['args'], command['kwargs']\n",
    "\n",
    "def receive_commands(worker_ids):\n",
    "    print('Placeholder print for receiving commands from workers in the following list')\n",
    "    print(worker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_command(partial_func):\n",
    "    func = partial_func.func\n",
    "    args = partial_func.args\n",
    "    kwargs = partial_func.keywords\n",
    "    command = {}\n",
    "    command['command'] = func.__name__\n",
    "    command['command_type'] = type(func)\n",
    "    command['args'] = args\n",
    "    command['kwargs'] = kwargs\n",
    "    command['arg_types'] = [type(x) for x in args]\n",
    "    command['kwarg_types'] = [type(kwargs[x]) for x in kwargs]\n",
    "    return command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hook'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hooking happens ([back to var](#var_test))\n",
    "Timing is to see how much overhead we've added.  Nothing says this should scale linearly, but it's a quick benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 36.6 ms, total: 1.3 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in range(100000):\n",
    "    y = torch.FloatTensor([[2,2],[2,2]])\n",
    "    z = torch.FloatTensor([[1,1],[1,1]])\n",
    "    res = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooking Variable\n",
      "Hooking <class 'torch.FloatTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n",
      "abs\n",
      "abs_\n",
      "acos\n",
      "acos_\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "apply_\n",
      "asin\n",
      "asin_\n",
      "atan\n",
      "atan2\n",
      "atan2_\n",
      "atan_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli\n",
      "bernoulli_\n",
      "bmm\n",
      "btrifact\n",
      "btrisolve\n",
      "byte\n",
      "cauchy_\n",
      "ceil\n",
      "ceil_\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cos\n",
      "cos_\n",
      "cosh\n",
      "cosh_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "de  skipped\n",
      "diag\n",
      "dim\n",
      "dist\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "eig\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "erf\n",
      "erf_\n",
      "erfinv\n",
      "erfinv_\n",
      "exp\n",
      "exp_\n",
      "expand\n",
      "expand_as\n",
      "exponential_\n",
      "fill_\n",
      "float\n",
      "floor\n",
      "floor_\n",
      "fmod\n",
      "fmod_\n",
      "frac\n",
      "frac_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "gels\n",
      "geometric_\n",
      "geqrf\n",
      "ger\n",
      "gesv\n",
      "get  skipped\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "histc\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "inverse\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "lerp\n",
      "lerp_\n",
      "lgamma\n",
      "lgamma_\n",
      "log\n",
      "log1p\n",
      "log1p_\n",
      "log_\n",
      "log_normal_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "mean\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "multinomial\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "neg\n",
      "neg_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "norm\n",
      "normal_\n",
      "numel  skipped\n",
      "numpy\n",
      "old__repr__  skipped\n",
      "orgqr\n",
      "ormqr\n",
      "permute\n",
      "pin_memory\n",
      "potrf\n",
      "potri\n",
      "potrs\n",
      "pow\n",
      "pow_\n",
      "process_command  skipped\n",
      "prod\n",
      "pstrf\n",
      "put_\n",
      "qr\n",
      "random_\n",
      "reciprocal\n",
      "reciprocal_\n",
      "remainder\n",
      "remainder_\n",
      "renorm\n",
      "renorm_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "round\n",
      "round_\n",
      "rsqrt\n",
      "rsqrt_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "send  skipped\n",
      "ser  skipped\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sigmoid\n",
      "sigmoid_\n",
      "sign\n",
      "sign_\n",
      "sin\n",
      "sin_\n",
      "sinh\n",
      "sinh_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "sqrt\n",
      "sqrt_\n",
      "squeeze\n",
      "squeeze_\n",
      "std\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "svd\n",
      "symeig\n",
      "t\n",
      "t_\n",
      "take\n",
      "tan\n",
      "tan_\n",
      "tanh\n",
      "tanh_\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "trtrs\n",
      "trunc\n",
      "trunc_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "uniform_\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "var\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.DoubleTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n",
      "abs\n",
      "abs_\n",
      "acos\n",
      "acos_\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "apply_\n",
      "asin\n",
      "asin_\n",
      "atan\n",
      "atan2\n",
      "atan2_\n",
      "atan_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli\n",
      "bernoulli_\n",
      "bmm\n",
      "btrifact\n",
      "btrisolve\n",
      "byte\n",
      "cauchy_\n",
      "ceil\n",
      "ceil_\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cos\n",
      "cos_\n",
      "cosh\n",
      "cosh_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "diag\n",
      "dim\n",
      "dist\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "eig\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "erf\n",
      "erf_\n",
      "erfinv\n",
      "erfinv_\n",
      "exp\n",
      "exp_\n",
      "expand\n",
      "expand_as\n",
      "exponential_\n",
      "fill_\n",
      "float\n",
      "floor\n",
      "floor_\n",
      "fmod\n",
      "fmod_\n",
      "frac\n",
      "frac_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "gels\n",
      "geometric_\n",
      "geqrf\n",
      "ger\n",
      "gesv\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "histc\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "inverse\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "lerp\n",
      "lerp_\n",
      "lgamma\n",
      "lgamma_\n",
      "log\n",
      "log1p\n",
      "log1p_\n",
      "log_\n",
      "log_normal_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "mean\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "multinomial\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "neg\n",
      "neg_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "norm\n",
      "normal_\n",
      "numel  skipped\n",
      "numpy\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "orgqr\n",
      "ormqr\n",
      "permute\n",
      "pin_memory\n",
      "potrf\n",
      "potri\n",
      "potrs\n",
      "pow\n",
      "pow_\n",
      "prod\n",
      "pstrf\n",
      "put_\n",
      "qr\n",
      "random_\n",
      "reciprocal\n",
      "reciprocal_\n",
      "remainder\n",
      "remainder_\n",
      "renorm\n",
      "renorm_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "round\n",
      "round_\n",
      "rsqrt\n",
      "rsqrt_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sigmoid\n",
      "sigmoid_\n",
      "sign\n",
      "sign_\n",
      "sin\n",
      "sin_\n",
      "sinh\n",
      "sinh_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "sqrt\n",
      "sqrt_\n",
      "squeeze\n",
      "squeeze_\n",
      "std\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "svd\n",
      "symeig\n",
      "t\n",
      "t_\n",
      "take\n",
      "tan\n",
      "tan_\n",
      "tanh\n",
      "tanh_\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "trtrs\n",
      "trunc\n",
      "trunc_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "uniform_\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "var\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.HalfTensor'>\n",
      "==============\n",
      "__add__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__idiv__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ipow__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "_cdata  skipped\n",
      "_torch  skipped\n",
      "apply_\n",
      "byte\n",
      "char\n",
      "chunk\n",
      "copy_\n",
      "cpu\n",
      "cuda\n",
      "data  skipped\n",
      "data_ptr\n",
      "dim\n",
      "double\n",
      "element_size\n",
      "expand_as\n",
      "float\n",
      "half\n",
      "int\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "long\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "matmul\n",
      "narrow\n",
      "ndimension  skipped\n",
      "nelement  skipped\n",
      "new\n",
      "numel  skipped\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "permute\n",
      "pin_memory\n",
      "repeat\n",
      "resize_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "size  skipped\n",
      "split\n",
      "squeeze\n",
      "squeeze_\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "tolist\n",
      "transpose\n",
      "transpose_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "view_as\n",
      "\n",
      "Hooking <class 'torch.ByteTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "all\n",
      "any\n",
      "apply_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli_\n",
      "bmm\n",
      "byte\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "diag\n",
      "dim\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "expand\n",
      "expand_as\n",
      "fill_\n",
      "float\n",
      "fmod\n",
      "fmod_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "geometric_\n",
      "ger\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "numel  skipped\n",
      "numpy\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "permute\n",
      "pin_memory\n",
      "prod\n",
      "put_\n",
      "random_\n",
      "remainder\n",
      "remainder_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sign\n",
      "sign_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "squeeze\n",
      "squeeze_\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "t\n",
      "t_\n",
      "take\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.CharTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "apply_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli_\n",
      "bmm\n",
      "byte\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "diag\n",
      "dim\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "expand\n",
      "expand_as\n",
      "fill_\n",
      "float\n",
      "fmod\n",
      "fmod_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "geometric_\n",
      "ger\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "numel  skipped\n",
      "numpy\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "permute\n",
      "pin_memory\n",
      "prod\n",
      "put_\n",
      "random_\n",
      "remainder\n",
      "remainder_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sign\n",
      "sign_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "squeeze\n",
      "squeeze_\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "t\n",
      "t_\n",
      "take\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.ShortTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n",
      "abs\n",
      "abs_\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "apply_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli_\n",
      "bmm\n",
      "byte\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "diag\n",
      "dim\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "expand\n",
      "expand_as\n",
      "fill_\n",
      "float\n",
      "fmod\n",
      "fmod_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "geometric_\n",
      "ger\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "neg\n",
      "neg_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "numel  skipped\n",
      "numpy\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "permute\n",
      "pin_memory\n",
      "prod\n",
      "put_\n",
      "random_\n",
      "remainder\n",
      "remainder_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sign\n",
      "sign_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "squeeze\n",
      "squeeze_\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "t\n",
      "t_\n",
      "take\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.IntTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs\n",
      "abs_\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "apply_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli_\n",
      "bmm\n",
      "byte\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "diag\n",
      "dim\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "expand\n",
      "expand_as\n",
      "fill_\n",
      "float\n",
      "fmod\n",
      "fmod_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "geometric_\n",
      "ger\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "neg\n",
      "neg_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "numel  skipped\n",
      "numpy\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "permute\n",
      "pin_memory\n",
      "prod\n",
      "put_\n",
      "random_\n",
      "remainder\n",
      "remainder_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sign\n",
      "sign_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "squeeze\n",
      "squeeze_\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "t\n",
      "t_\n",
      "take\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.LongTensor'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__delitem__\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__getstate__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_advanced_index_select\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index\n",
      "_sparse_mask\n",
      "_torch  skipped\n",
      "_write_metadata\n",
      "abs\n",
      "abs_\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "apply_\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli_\n",
      "bmm\n",
      "byte\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clamp_\n",
      "clone\n",
      "contiguous\n",
      "copy_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "diag\n",
      "dim\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "element_size\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "expand\n",
      "expand_as\n",
      "fill_\n",
      "float\n",
      "fmod\n",
      "fmod_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "geometric_\n",
      "ger\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "index\n",
      "index_add_\n",
      "index_copy_\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "is_contiguous\n",
      "is_cuda  skipped\n",
      "is_pinned\n",
      "is_same_size\n",
      "is_set_to\n",
      "is_shared\n",
      "is_signed\n",
      "is_sparse  skipped\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "map2_\n",
      "map_\n",
      "masked_copy_\n",
      "masked_fill_\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "mv\n",
      "narrow\n",
      "ndimension  skipped\n",
      "ne\n",
      "ne_\n",
      "neg\n",
      "neg_\n",
      "nelement  skipped\n",
      "new\n",
      "nonzero\n",
      "numel  skipped\n",
      "numpy\n",
      "old___new__  skipped\n",
      "old__repr__  skipped\n",
      "permute\n",
      "pin_memory\n",
      "prod\n",
      "put_\n",
      "random_\n",
      "remainder\n",
      "remainder_\n",
      "repeat\n",
      "resize_\n",
      "resize_as_\n",
      "scatter_\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "shape  skipped\n",
      "share_memory_\n",
      "short\n",
      "sign\n",
      "sign_\n",
      "size  skipped\n",
      "sort\n",
      "split\n",
      "squeeze\n",
      "squeeze_\n",
      "storage\n",
      "storage_offset\n",
      "storage_type  skipped\n",
      "stride\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "t\n",
      "t_\n",
      "take\n",
      "tolist\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "view\n",
      "view_as\n",
      "zero_\n",
      "\n",
      "Hooking <class 'torch.autograd.variable.Variable'>\n",
      "==============\n",
      "__add__\n",
      "__and__\n",
      "__bool__\n",
      "__class__  skipped\n",
      "__deepcopy__\n",
      "__delattr__  skipped\n",
      "__dict__  skipped\n",
      "__dir__  skipped\n",
      "__div__\n",
      "__doc__  skipped\n",
      "__eq__  skipped\n",
      "__float__\n",
      "__format__  skipped\n",
      "__ge__  skipped\n",
      "__getattr__  skipped\n",
      "__getattribute__  skipped\n",
      "__getitem__\n",
      "__gt__  skipped\n",
      "__hash__  skipped\n",
      "__iadd__\n",
      "__iand__\n",
      "__idiv__\n",
      "__ilshift__\n",
      "__imul__\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__ixor__\n",
      "__le__  skipped\n",
      "__len__\n",
      "__long__\n",
      "__lshift__\n",
      "__lt__  skipped\n",
      "__matmul__\n",
      "__mod__\n",
      "__module__  skipped\n",
      "__mul__\n",
      "__ne__  skipped\n",
      "__neg__\n",
      "__new__  skipped\n",
      "__nonzero__\n",
      "__or__\n",
      "__pow__\n",
      "__radd__\n",
      "__rdiv__\n",
      "__reduce__  skipped\n",
      "__reduce_ex__  skipped\n",
      "__repr__  skipped\n",
      "__rmul__\n",
      "__rpow__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__setattr__  skipped\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__  skipped\n",
      "__str__  skipped\n",
      "__sub__\n",
      "__subclasshook__  skipped\n",
      "__truediv__\n",
      "__weakref__  skipped\n",
      "__xor__\n",
      "_advanced_index_add\n",
      "_backward_hooks  skipped\n",
      "_execution_engine  skipped\n",
      "_fallthrough_methods  skipped\n",
      "_get_type\n",
      "_grad  skipped\n",
      "_grad_fn  skipped\n",
      "_torch  skipped\n",
      "_unnarrow\n",
      "_version  skipped\n",
      "abs\n",
      "abs_\n",
      "acos\n",
      "acos_\n",
      "add\n",
      "add_\n",
      "addbmm\n",
      "addbmm_\n",
      "addcdiv\n",
      "addcdiv_\n",
      "addcmul\n",
      "addcmul_\n",
      "addmm\n",
      "addmm_\n",
      "addmv\n",
      "addmv_\n",
      "addr\n",
      "addr_\n",
      "all\n",
      "any\n",
      "asin\n",
      "asin_\n",
      "atan\n",
      "atan2\n",
      "atan2_\n",
      "atan_\n",
      "backward\n",
      "baddbmm\n",
      "baddbmm_\n",
      "bernoulli\n",
      "bmm\n",
      "btrifact\n",
      "btrisolve\n",
      "byte\n",
      "cat  skipped\n",
      "ceil\n",
      "ceil_\n",
      "char\n",
      "chunk\n",
      "clamp\n",
      "clone\n",
      "contiguous\n",
      "cos\n",
      "cos_\n",
      "cosh\n",
      "cosh_\n",
      "cpu\n",
      "cross\n",
      "cuda\n",
      "cumprod\n",
      "cumsum\n",
      "data  skipped\n",
      "data_ptr\n",
      "detach\n",
      "detach_\n",
      "diag\n",
      "dist\n",
      "div\n",
      "div_\n",
      "dot\n",
      "double\n",
      "eig\n",
      "eq\n",
      "eq_\n",
      "equal\n",
      "erf\n",
      "erf_\n",
      "erfinv\n",
      "erfinv_\n",
      "exp\n",
      "exp_\n",
      "expand\n",
      "expand_as\n",
      "fill_\n",
      "float\n",
      "floor\n",
      "floor_\n",
      "fmod\n",
      "fmod_\n",
      "force_hook\n",
      "frac\n",
      "frac_\n",
      "gather\n",
      "ge\n",
      "ge_\n",
      "gels\n",
      "geometric_\n",
      "geqrf\n",
      "ger\n",
      "gesv\n",
      "get_device\n",
      "grad  skipped\n",
      "grad_fn  skipped\n",
      "gt\n",
      "gt_\n",
      "half\n",
      "histc\n",
      "index_add\n",
      "index_add_\n",
      "index_copy\n",
      "index_copy_\n",
      "index_fill\n",
      "index_fill_\n",
      "index_select\n",
      "int\n",
      "inverse\n",
      "is_contiguous\n",
      "is_leaf  skipped\n",
      "is_same_size\n",
      "is_set_to\n",
      "kthvalue\n",
      "le\n",
      "le_\n",
      "lerp\n",
      "lerp_\n",
      "lgamma\n",
      "lgamma_\n",
      "log\n",
      "log1p\n",
      "log1p_\n",
      "log_\n",
      "log_normal_\n",
      "long\n",
      "lt\n",
      "lt_\n",
      "masked_copy\n",
      "masked_copy_\n",
      "masked_fill\n",
      "masked_fill_\n",
      "masked_scatter\n",
      "masked_scatter_\n",
      "masked_select\n",
      "matmul\n",
      "max\n",
      "mean\n",
      "median\n",
      "min\n",
      "mm\n",
      "mode\n",
      "mul\n",
      "mul_\n",
      "multinomial\n",
      "mv\n",
      "narrow\n",
      "ne\n",
      "ne_\n",
      "neg\n",
      "neg_\n",
      "nonzero\n",
      "norm\n",
      "numel  skipped\n",
      "old_data  skipped\n",
      "old_grad  skipped\n",
      "ones_like  skipped\n",
      "orgqr\n",
      "ormqr\n",
      "output_nr  skipped\n",
      "permute\n",
      "potrf\n",
      "potri\n",
      "potrs\n",
      "pow\n",
      "pow_\n",
      "prod\n",
      "pstrf\n",
      "put_\n",
      "qr\n",
      "reciprocal\n",
      "reciprocal_\n",
      "register_hook\n",
      "reinforce\n",
      "remainder\n",
      "remainder_\n",
      "renorm\n",
      "repeat\n",
      "requires_grad  skipped\n",
      "resize\n",
      "resize_as\n",
      "retain_grad\n",
      "round\n",
      "round_\n",
      "rsqrt\n",
      "rsqrt_\n",
      "scatter\n",
      "scatter_\n",
      "scatter_add\n",
      "scatter_add_\n",
      "select\n",
      "set_\n",
      "short\n",
      "sigmoid\n",
      "sigmoid_\n",
      "sign\n",
      "sign_\n",
      "sin\n",
      "sin_\n",
      "sinh\n",
      "sinh_\n",
      "sort\n",
      "split\n",
      "sqrt\n",
      "sqrt_\n",
      "squeeze\n",
      "squeeze_\n",
      "std\n",
      "storage_offset\n",
      "sub\n",
      "sub_\n",
      "sum\n",
      "svd\n",
      "symeig\n",
      "t\n",
      "t_\n",
      "take\n",
      "tan\n",
      "tan_\n",
      "tanh\n",
      "tanh_\n",
      "topk\n",
      "trace\n",
      "transpose\n",
      "transpose_\n",
      "tril\n",
      "tril_\n",
      "triu\n",
      "triu_\n",
      "trtrs\n",
      "trunc\n",
      "trunc_\n",
      "type\n",
      "type_as\n",
      "unfold\n",
      "unsqueeze\n",
      "unsqueeze_\n",
      "var\n",
      "view\n",
      "view_as\n",
      "volatile  skipped\n",
      "zero_\n",
      "zeros_like  skipped\n",
      "\n",
      "CPU times: user 187 ms, sys: 37.9 ms, total: 225 ms\n",
      "Wall time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for attr in dir(torch):\n",
    "    if attr == 'typename':\n",
    "        continue\n",
    "    if type(torch.__getattribute__(attr)) in [FunctionType, BuiltinFunctionType]:\n",
    "        torch.__setattr__(attr, assign_workers_function(['A1','B1', 'B2'])(pass_func_args(torch.__getattribute__(attr))))\n",
    "\n",
    "# the first four can cause infinite recursion or internal type errors\n",
    "exclude = ['ndimension', 'nelement', 'size','numel', 'ser', 'de']\n",
    "var_exclude = ['__getattr__']\n",
    "\n",
    "print(\"Hooking Variable\")\n",
    "hook_var_force_hook()\n",
    "hook_var___init__(service_self)\n",
    "hook_var___new__(service_self)\n",
    "hook_var_contents(service_self)\n",
    "\n",
    "for tensor_type in tensorvar_types:\n",
    "    print('Hooking {}'.format(tensor_type))\n",
    "    print('==============')\n",
    "    if tensor_type is not torch.FloatTensor and tensor_type is not torch.autograd.variable.Variable:\n",
    "        #hook_tensor___init__(service_self, tensor_type)\n",
    "        hook_tensor___new__(service_self, tensor_type)\n",
    "        hook_tensor___repr__(service_self, tensor_type)\n",
    "    for attr in dir(tensor_type):\n",
    "        if (tensor_type == torch.autograd.variable.Variable and attr in var_exclude) or attr in exclude:\n",
    "            print(attr,' skipped')\n",
    "            continue\n",
    "        lit = getattr(tensor_type, attr)\n",
    "        is_desc = inspect.ismethoddescriptor(lit)\n",
    "        is_func = type(lit)==FunctionType\n",
    "        is_mappingproxy = attr == '__dict__'\n",
    "        try:\n",
    "            is_service_func = 'TorchService' in lit.__qualname__\n",
    "        except:\n",
    "            is_service_func = False\n",
    "        is_base = attr in dir(object)\n",
    "        is_old = re.match('old*', attr) is not None\n",
    "        if (is_desc or (is_func and not is_service_func)) and not is_base and not is_old:\n",
    "            print(attr)\n",
    "            setattr(tensor_type, 'old_{}'.format(attr), lit)\n",
    "            setattr(tensor_type, attr, assign_workers_method(['A1','B1', 'B2'])(pass_method_args(lit)))\n",
    "        else:\n",
    "            print(attr, ' skipped')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 527 ms, total: 2.69 s\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in range(100000):\n",
    "    y = torch.FloatTensor([[2,2],[2,2]])\n",
    "    z = torch.FloatTensor([[1,1],[1,1]])\n",
    "    res = y.add(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tests'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests [(top)](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='float_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "9324432963\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  2\n",
       " 2  2\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "normal_\n",
      "[<class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "normal_\n",
      "[<class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "normal_\n",
      "[<class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ torch.FloatTensor - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "uniform_\n",
      "[<class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "uniform_\n",
      "[<class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "uniform_\n",
      "[<class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ torch.FloatTensor - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.FloatTensor'>, <class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.FloatTensor'>, <class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.FloatTensor'>, <class 'torch.FloatTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ torch.FloatTensor - Location:other_guy ],\n",
       "  [ torch.FloatTensor - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booped!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.add(x,y) # This should throw an error, since their attributes say they're not on the same machine.\n",
    "except NotImplementedError:\n",
    "    print('booped!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='double_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoubleTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.DoubleTensor([[2,2],[2,2]])\n",
    "z = torch.DoubleTensor(([[1,1],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "5171645209\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.DoubleTensor of size 2x2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.DoubleTensor of size 2x2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.DoubleTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "normal_\n",
      "[<class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "normal_\n",
      "[<class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "normal_\n",
      "[<class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.DoubleTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "uniform_\n",
      "[<class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "uniform_\n",
      "[<class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "uniform_\n",
      "[<class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.DoubleTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.DoubleTensor'>, <class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.DoubleTensor'>, <class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.DoubleTensor'>, <class 'torch.DoubleTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.DoubleTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.DoubleTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='half_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HalfTensor\n",
    "This one's weird, I think it might be underdeveloped on their end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.HalfTensor([[2,2],[2,2]])\n",
    "z = torch.HalfTensor(([[1,1],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  2\n",
       " 2  2\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.is_pointer_to_remote = True\n",
    "y.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "float\n",
      "[<class 'torch.HalfTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "float\n",
      "[<class 'torch.HalfTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "float\n",
      "[<class 'torch.HalfTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.HalfTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.HalfTensor'>, <class 'torch.HalfTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.HalfTensor'>, <class 'torch.HalfTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.HalfTensor'>, <class 'torch.HalfTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.HalfTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.HalfTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.HalfTensor([[2,2],[2,2]])\n",
    "b = torch.HalfTensor(([[1,1],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HalfTensor is weird\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.add(a,b)\n",
    "except:\n",
    "    print('HalfTensor is weird')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='byte_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ByteTensor([[0,1],[1,0]])\n",
    "z = torch.ByteTensor(([[0,0],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 1  1\n",
       "[torch.ByteTensor of size 2x2]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 255  255\n",
       " 255  255\n",
       "[torch.ByteTensor of size 2x2]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.fill_(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "6447598411\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1\n",
       " 2  1\n",
       "[torch.ByteTensor of size 2x2]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  2\n",
       " 1  1\n",
       "[torch.ByteTensor of size 2x2]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.ByteTensor of size 2x2]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  1\n",
      " 2  1\n",
      "[torch.ByteTensor of size 2x2]\n",
      "\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.ByteTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  2\n",
      " 1  1\n",
      "[torch.ByteTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.t_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "t\n",
      "[<class 'torch.ByteTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "t\n",
      "[<class 'torch.ByteTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "t\n",
      "[<class 'torch.ByteTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.ByteTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.ByteTensor'>, <class 'torch.ByteTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.ByteTensor'>, <class 'torch.ByteTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.ByteTensor'>, <class 'torch.ByteTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.ByteTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.ByteTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='char_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CharTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.CharTensor([[0,1],[1,0]])\n",
    "z = torch.CharTensor(([[0,0],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 1  1\n",
       "[torch.CharTensor of size 2x2]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1 -1\n",
       "-1 -1\n",
       "[torch.CharTensor of size 2x2]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.fill_(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "3428024029\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1\n",
       " 2  1\n",
       "[torch.CharTensor of size 2x2]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  2\n",
       " 1  1\n",
       "[torch.CharTensor of size 2x2]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.CharTensor of size 2x2]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  1\n",
      " 2  1\n",
      "[torch.CharTensor of size 2x2]\n",
      "\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.CharTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  2\n",
      " 1  1\n",
      "[torch.CharTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.t_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "t\n",
      "[<class 'torch.CharTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "t\n",
      "[<class 'torch.CharTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "t\n",
      "[<class 'torch.CharTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.CharTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.CharTensor'>, <class 'torch.CharTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.CharTensor'>, <class 'torch.CharTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.CharTensor'>, <class 'torch.CharTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.CharTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.CharTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='short_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShortTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ShortTensor([[1,2],[3,4]])\n",
    "z = torch.ShortTensor(([[1,1],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "11527967\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3\n",
       " 4  5\n",
       "[torch.ShortTensor of size 2x2]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  4\n",
       " 3  5\n",
       "[torch.ShortTensor of size 2x2]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.ShortTensor of size 2x2]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3\n",
      " 4  5\n",
      "[torch.ShortTensor of size 2x2]\n",
      "\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.ShortTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  4\n",
      " 3  5\n",
      "[torch.ShortTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.t_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "t\n",
      "[<class 'torch.ShortTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "t\n",
      "[<class 'torch.ShortTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "t\n",
      "[<class 'torch.ShortTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.ShortTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.ShortTensor'>, <class 'torch.ShortTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.ShortTensor'>, <class 'torch.ShortTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.ShortTensor'>, <class 'torch.ShortTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.ShortTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.ShortTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='int_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IntTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.IntTensor([[1,2],[3,4]])\n",
    "z = torch.IntTensor(([[1,1],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "8865562600\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3\n",
       " 4  5\n",
       "[torch.IntTensor of size 2x2]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  4\n",
       " 3  5\n",
       "[torch.IntTensor of size 2x2]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  0\n",
       "[torch.IntTensor of size 2x2]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3\n",
      " 4  5\n",
      "[torch.IntTensor of size 2x2]\n",
      "\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.IntTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  4\n",
      " 3  5\n",
      "[torch.IntTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.t_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "t\n",
      "[<class 'torch.IntTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "t\n",
      "[<class 'torch.IntTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "t\n",
      "[<class 'torch.IntTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.IntTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.IntTensor'>, <class 'torch.IntTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.IntTensor'>, <class 'torch.IntTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.IntTensor'>, <class 'torch.IntTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.IntTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.IntTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='long_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor([[1,2],[3,4]])\n",
    "z = torch.LongTensor(([[1,1],[1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmXJMbiCqQdFCUjwy63GMUDDKCfEabJRYo2RHPjheCW8mc'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "5264969863\n"
     ]
    }
   ],
   "source": [
    "print(x.is_pointer_to_remote)\n",
    "print(x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  4\n",
       " 3  5\n",
       "[torch.LongTensor of size 2x2]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  4\n",
       " 3  5\n",
       "[torch.LongTensor of size 2x2]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  4   8\n",
       "  6  10\n",
       "[torch.LongTensor of size 2x2]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case when tensor isn't local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.is_pointer_to_remote = True\n",
    "x.owner = 'other_guy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "t\n",
      "[<class 'torch.LongTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "t\n",
      "[<class 'torch.LongTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "t\n",
      "[<class 'torch.LongTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.LongTensor'> - Location:other_guy ],), {})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "add\n",
      "[<class 'torch.LongTensor'>, <class 'torch.LongTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "add\n",
      "[<class 'torch.LongTensor'>, <class 'torch.LongTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "add\n",
      "[<class 'torch.LongTensor'>, <class 'torch.LongTensor'>]\n",
      "[]\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([ <class 'torch.LongTensor'> - Location:other_guy ],\n",
       "  [ <class 'torch.LongTensor'> - Location:other_guy ]),\n",
       " {})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='var_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Variable [(back to hook)](#hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Variable(torch.FloatTensor([[1,2],[3,4]]), requires_grad = True)\n",
    "z = Variable(torch.FloatTensor(([[1,1],[1,1]])), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data_registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmXJMbiCqQdFCUjwy63GMUDDKCfEabJRYo2RHPjheCW8mc'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmXJMbiCqQdFCUjwy63GMUDDKCfEabJRYo2RHPjheCW8mc'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmXJMbiCqQdFCUjwy63GMUDDKCfEabJRYo2RHPjheCW8mc'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384345516"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2\n",
       " 3  4\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5976705432"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_self.register_object(x.data, False).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmXJMbiCqQdFCUjwy63GMUDDKCfEabJRYo2RHPjheCW8mc'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3\n",
       " 4  5\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data_registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data_registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data_registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3\n",
       " 4  5\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Make sure data_registered and grad_registered are set to False on leaf variable grads (likely through force_hook above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5987102910"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
