{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from grid.ipfsapi.client import Client\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import base64\n",
    "from bitcoin import base58\n",
    "from threading import Thread\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" This module contains an implementation of an IPFS\n",
    "version-control system, which is structured as a directed in-tree with nodes\n",
    "represented by the bytes representation of the VersionTreeNode class. \"\"\"\n",
    "from typing import Optional, Iterator\n",
    "\n",
    "from grid import ipfsapi\n",
    "\n",
    "# TODO: Unit tests.\n",
    "# TODO: Do we want to store the hash on the node after it's been committed?\n",
    "class VersionTreeNode:\n",
    "    \"\"\" Thin wrapper around a piece of IPFS-versioned data and the\n",
    "    IPFS multihash of its parent. \"\"\"\n",
    "    # Delimiter for serializing packed object. Should not be alphanumeric.\n",
    "    DELIMITER = b\"|\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 contents: bytes,\n",
    "                 id_hash: Optional[str] = None,\n",
    "                 parent_hash: Optional[str] = None,\n",
    "                 ipfs_client: ipfsapi.Client = None):\n",
    "        \"\"\" parent_hash is a UTF-8 IPFS multihash identifying\n",
    "        this node's parent in the version tree. If parent_hash is None,\n",
    "        this node is the root of a version tree. \"\"\"\n",
    "        self.contents = contents\n",
    "        # Convert empty string to None to minimize typing bugs.\n",
    "        self.id_hash = id_hash or None\n",
    "        self.parent_hash = parent_hash or None\n",
    "        self.ipfs_client = ipfs_client\n",
    "\n",
    "    def commit(self, ipfs_client: ipfsapi.Client = None) -> str:\n",
    "        \"\"\" Commits the node to the version tree, and returns the\n",
    "        UTF-8 multihash representing its IPFS ID\"\"\"\n",
    "        \n",
    "        self.id_hash = (ipfs_client or self.ipfs_client).add_bytes(self.to_bytes())\n",
    "        return self.id_hash\n",
    "    \n",
    "    @classmethod\n",
    "    def get_node_by_hash(cls,\n",
    "                         multihash: str,\n",
    "                         ipfs_client: ipfsapi.Client) -> \"VersionTreeNode\":\n",
    "        \"\"\" Retrieve and deserialize a VersionTreeNode addressed\n",
    "        by it's UTF-8 multihash IPFS ID. \"\"\"\n",
    "        return cls.from_bytes(ipfs_client.cat(multihash))\n",
    "\n",
    "    def get_with_ancestors(\n",
    "            self,\n",
    "            ipfs_client: ipfsapi.Client = None) -> Iterator[\"VersionTreeNode\"]:\n",
    "        \"\"\" Return an iterator containing this node and all its\n",
    "        direct ancestors in the version tree, in that order. \"\"\"\n",
    "        yield self\n",
    "        parent_hash = self.parent_hash\n",
    "        while parent_hash is not None:\n",
    "            parent_node = self.get_node_by_hash(\n",
    "                parent_hash,\n",
    "                (ipfs_client or self.ipfs_client))\n",
    "            parent_hash = parent_node.parent_hash\n",
    "            yield parent_node\n",
    "\n",
    "    @classmethod\n",
    "    def get_node_with_ancestors_by_hash(\n",
    "            cls,\n",
    "            multihash: str,\n",
    "            ipfs_client: ipfsapi.Client) -> Iterator[\"VersionTreeNode\"]:\n",
    "        \"\"\" Convenience method to get an iterator of the node identified by the\n",
    "        provided UTF-8 IPFS multihash, along with all of its ancestors, in\n",
    "        that order.\"\"\"\n",
    "        return cls.get_node_by_hash(\n",
    "            multihash, ipfs_client).get_with_ancestors(ipfs_client)\n",
    "\n",
    "    def to_bytes(self) -> bytes:\n",
    "        \"\"\" For contents b\"foo\", parent_hash \"bar\", and DELIMITER b\"|\",\n",
    "        returns b\"foo|bar\" \"\"\"\n",
    "        parent_hash_bytes = self.parent_hash.encode(\"utf-8\") if \\\n",
    "            self.parent_hash else \\\n",
    "            b\"\"\n",
    "        id_hash_bytes = self.id_hash.encode(\"utf-8\") if \\\n",
    "            self.id_hash else \\\n",
    "            b\"\"\n",
    "        return self.DELIMITER.join((self.contents, id_hash_bytes, parent_hash_bytes))\n",
    "\n",
    "    @classmethod\n",
    "    def from_bytes(cls, b: bytes) -> \"VersionTreeNode\":\n",
    "        \"\"\" In case the contents section happens to contain the DELIMITER\n",
    "        string, only splits on the final occurrence of DELIMITER. The\n",
    "        multihash is hexadecimal, so it won't contain the non-hex DELIMITER.\"\"\"\n",
    "        contents, id_hash_bytes, parent_hash_bytes = b.rsplit(cls.DELIMITER, maxsplit=1)\n",
    "        return cls(contents, id_hash_bytes.decode(\"utf-8\"), parent_hash_bytes.decode(\"utf-8\"))\n",
    "    \n",
    "    def to_json(self):\n",
    "        message = {'id_hash': self.id_hash, 'parent_hash': self.parent_hash}\n",
    "        return json.dumps(message)\n",
    "    \n",
    "    def publish_children(self, ipfs_client: ipfsapi.Client):\n",
    "        \n",
    "        channel = 'children_of_' + str(self.parent_hash)\n",
    "        \n",
    "        ipfs_client.pubsub_pub(topic = channel, payload=self.to_json())\n",
    "        \n",
    "    def listen_for_children(self, ipfs_client: ipfsapi.Client):\n",
    "        channel = 'children_of_' + str(self.parent_hash)\n",
    "        def extract_data(message):\n",
    "            return message['data']\n",
    "        return self.listen_to_channel_sync(ipfs_client, channel, extract_data)\n",
    "        \n",
    "    def listen_to_channel_sync(self, *args):\n",
    "        \"\"\"\n",
    "        Synchronous version of listen_to_channel\n",
    "        \"\"\"\n",
    "\n",
    "        return self.listen_to_channel_impl(*args)\n",
    "\n",
    "    def listen_to_channel(self, *args):\n",
    "        \"\"\"\n",
    "        Listens for IPFS pubsub sub messages asynchronously.\n",
    "        This function will create the listener and call back your handler\n",
    "        function on a new thread.\n",
    "        \"\"\"\n",
    "        t1 = Thread(target=self.listen_to_channel_impl, args=args)\n",
    "        return t1.start()\n",
    "\n",
    "    def listen_to_channel_impl(self,\n",
    "                               ipfs_client: ipfsapi.Client,\n",
    "                               channel,\n",
    "                               handle_message,\n",
    "                               init_function=None,\n",
    "                               ignore_from_self=False):\n",
    "        \"\"\"\n",
    "        Do not call directly.  Use listen_to_channel or listen_to_channel_sync instead.\n",
    "        \"\"\"\n",
    "\n",
    "        first_proc = True\n",
    "\n",
    "        #if channel not in self.subscribed:\n",
    "        new_messages = ipfs_client.pubsub_sub(topic=channel, stream=True)\n",
    "        #self.subscribed.append(channel)\n",
    "\n",
    "        #else:\n",
    "        #    return\n",
    "\n",
    "        # new_messages is a generator which will keep yield new messages until\n",
    "        # you return from the loop. If you do return from the loop, we will no\n",
    "        # longer be subscribed.\n",
    "        for m in new_messages:\n",
    "            if init_function is not None and first_proc:\n",
    "                init_function()\n",
    "                first_proc = False\n",
    "\n",
    "            message = self.decode_message(m)\n",
    "            if message is not None:\n",
    "                fr = base58.encode(message['from'])\n",
    "                if not ignore_from_self or fr != self.id:\n",
    "                    out = handle_message(message)\n",
    "                    if out is not None:\n",
    "                        print(out)\n",
    "                        return out\n",
    "                else:\n",
    "                    print('ignore mssage from self')\n",
    "\n",
    "    def decode_message(self, encoded):\n",
    "        if ('from' in encoded):\n",
    "            decoded = {}\n",
    "            decoded['from'] = base64.standard_b64decode(encoded['from'])\n",
    "            decoded['data'] = base64.standard_b64decode(\n",
    "                encoded['data']).decode('ascii')\n",
    "            decoded['seqno'] = base64.standard_b64decode(encoded['seqno'])\n",
    "            decoded['topicIDs'] = encoded['topicIDs']\n",
    "            decoded['encoded'] = encoded\n",
    "            return decoded\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When commit publish on channel children of\n",
    "# When commit listen for children\n",
    "# Will have to include in the VersionTreeNode the ipfs address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "om = 'openmined'\n",
    "\n",
    "#children_of = f'{om}:children_of'\n",
    "def children_of(id):\n",
    "    channel = \"children_of_\" + str(id)\n",
    "    return channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import grid.ipfsapi.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'children_of_4353'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children_of(4353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message = {'content' : [34,6,624,546], 'parent_id': '4353'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.pubsub_pub(topic = children_of(4353), payload=json.dumps(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x02\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00i8q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x10-\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([45,356])\n",
    "pickle.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1 = VersionTreeNode(contents=pickle.dumps(data),parent_hash='4353',ipfs_client=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmW12KVNRP83k4hUaKARWbse32wbocrZvKTgUkKsf8KG1a'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1.publish_children(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id_hash\": \"QmXBof6uxEcvWXCdrnas6ewxTxZHNzEUHrNgBY9A5hThTp\", \"parent_hash\": \"4353\"}\n"
     ]
    }
   ],
   "source": [
    "yo = n1.listen_for_children(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ya = json.loads(yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-5ca00dd9dae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_by_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_hash'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-195-851a5dd0d362>\u001b[0m in \u001b[0;36mget_node_by_hash\u001b[0;34m(cls, multihash, ipfs_client)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\" Retrieve and deserialize a VersionTreeNode addressed\n\u001b[1;32m     42\u001b[0m         by it's UTF-8 multihash IPFS ID. \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipfs_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultihash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     def get_with_ancestors(\n",
      "\u001b[0;32m<ipython-input-195-851a5dd0d362>\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(cls, b)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly\u001b[0m \u001b[0msplits\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0moccurrence\u001b[0m \u001b[0mof\u001b[0m \u001b[0mDELIMITER\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         multihash is hexadecimal, so it won't contain the non-hex DELIMITER.\"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_hash_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_hash_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDELIMITER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_hash_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_hash_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "n1.get_node_by_hash(ya['id_hash'],c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L.append(yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:openmined2]",
   "language": "python",
   "name": "conda-env-openmined2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
